## 数据倾斜的表现
- Spark引擎的大部分task执行时间比较一致，但是存在一些task的执行时间特别长，例如，500个task，其中498个执行较快，10分钟执行完成，剩余的两个task需要执行半个小时以上。
- 例行化执行的代码，某一天发生OOM问题，大概率是有数据倾斜了。

数据倾斜产生的原因是：shuffle的时候，需要将各个节点的相同的key拉取到同一个节点上，如果这个key对应的数据量非常大的时候，就会发生数据倾斜。

数据倾斜只会发生在shuffle过程中，Spark引擎会触发Shuffle的RDD算子有：distinct、join、repartition、reduceByKey、groupByKey、aggregateByKey

### 调整并行度
需要Shuffle的操作算子上直接设置并行度或者使用spark.default.parallelism设置。如果是Spark SQL，还可通过SET spark.sql.shuffle.partitions=num_tasks设置并行度。

该方法使用场景少，只能缓解数据倾斜，不能彻底解决数据倾斜。

### Map side join

通过Spark的Broadcast机制，将Reduce Join转化为Map Join，避免Shuffle，从而完全消除Shuffle带来的数据倾斜。

参与Join的一侧数据集足够小，并且主要适用于Join的场景，不适合聚合的场景，适用条件有限。

### 异常值过滤

