MLlib是Spark的机器学习（ML）库，目标是使实际的机器学习变得可扩展和容易，提供了以下工具：
ML算法：

- 常见的学习算法，如分类、回归、聚类和协同过滤。
- 特征工具：特征提取、转换、降维和选择
- Pipeline：构建、评估和调优的工具
- 持久化：保存和加载算法、模型和Pipeline
- 实用性工具：线性代数、统计、数据处理等


协同过滤通常用于推荐系统，该技术的目的是填充user-item关联矩阵中的缺失值。spark.ml库目前支持基于模型的协同过滤：使用潜在小的因素集来表示用户和物品，用来预测缺失值。
spark.ml使用交替最小二乘算法(ALS)来学习这些潜在因素，在实现中具有以下参数：

- numBlocks，为了并行化计算，将用户和物品划分的块数，默认为10
- rank，模型中潜在因素的数量，默认为10
- maxIter，模型迭代轮次，默认为10

基于矩阵分解的协同过滤的标准方法将user-item矩阵中的值视为user对item的明确偏好，例如，用户给电影的评分。

在现实世界中，通常只能获取隐式反馈（例如，曝光、点击、购买、喜欢、分享等）。spark.ml中对这些数据处理的方法来自于[用于隐式反馈数据集的协同过滤](https://ieeexplore.ieee.org/document/4781121/)。从本质上讲，这种方法没有试图直接对评分矩阵建模，而是将数据视为表示用户行为观察强度的数字（如点击次数，观看电影的累计持续时间）。这些数字与用户偏好的可信度有关，而不是对项目的明确评分。该模型试图找出可以预测用户对某个商品预期偏好的潜在因素。


冷启动策略
使用ALS模型预测时，经常会遇到再训练模型期间不存在的的user或者item，通常有两种情况
1. 在生产过程中，对于新用户或者item，没有评分历史且模型没有训练（冷启动问题）
2.在交叉训练过程中，数据集被切分为训练集和验证集。基于Spark的CrossValidator或者TrainValidationSplit进行简单随机切分是，通常会遇到在验证集出现的用户或者item，但是并不会在训练集中出现。

默认情况下，Spark在使用 ALSModel.transform预测时，当用户或者item在模型中不存在时，通常会设置为NaN，这在生产环境中非常有用，因为它说明了这是一个新用户或者item，系统可以做出回退的决定，用作预测。

然而，这在交叉验证中是不可取的，因为任何Nan的预测值，都会导致评估结果的Nan值（例如当使用RegressionEvaluator），这使得模型选择变得不可能。

Spark允许将coldStartStrategy参数设置为drop，以便删除预测结果中包含NaN值得行；评估结果会基于非NaN值得数据。